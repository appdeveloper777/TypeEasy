#!/usr/bin/env python3
"""
Gemini AI Service for TypeEasy WhatsApp Agent

Este servicio expone la API de Gemini para conversaciones inteligentes
con manejo de contexto conversacional.
"""

import os
import logging
from datetime import datetime
from flask import Flask, request, jsonify
import google.generativeai as genai

# Configuraci√≥n de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# Configuraci√≥n de Gemini
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
GEMINI_MODEL = os.environ.get('GEMINI_MODEL', 'models/gemini-1.5-flash-001')

if not GEMINI_API_KEY:
    logger.warning('‚ö†Ô∏è  GEMINI_API_KEY no configurada. El servicio no funcionar√° correctamente.')
else:
    genai.configure(api_key=GEMINI_API_KEY)
    logger.info(f'‚úÖ Gemini configurado con modelo: {GEMINI_MODEL}')

# Almacenamiento de historial conversacional en memoria
# Estructura: {from_number: [{"role": "user", "parts": ["mensaje"]}, ...]}
conversation_history = {}

# L√≠mite de mensajes en historial por usuario
MAX_HISTORY_LENGTH = 10

# Prompt del sistema para configurar el comportamiento del bot
SYSTEM_PROMPT = """Eres el Asistente Virtual experto de 'Rollers Per√∫', una empresa l√≠der en venta de cortinas tipo Roller.

TU OBJETIVO PRINCIPAL:
Ayudar al cliente a cotizar sus rollers. Para eso, es INDISPENSABLE que les ayudes a TOMAR LAS MEDIDAS de sus ventanas correctamente.

TUS FUNCIONES:
1. Asesorar sobre tipos de tela (Blackout, Screen, Duo).
2. Guiar paso a paso en la TOMA DE MEDIDAS (Tu prioridad).
3. Cotizar aproximados (si te dan medidas).

CAT√ÅLOGO DE PRODUCTOS:
- Roller Blackout (Bloqueo total de luz): Ideal para dormitorios. Desde S/. 90 m2.
- Roller Screen (Paso de luz, visibilidad exterior, filtro UV): Ideal para salas. Desde S/. 110 m2.
- Roller Duo (Zebra - Franjas opacas y trasl√∫cidas): Moderno y vers√°til. Desde S/. 140 m2.

GU√çA PARA TOMAR MEDIDAS (Sigue estos pasos estrictamente):

Paso 1: Preguntar el tipo de instalaci√≥n
- "¬øLa instalaci√≥n ser√° DENTRO del marco de la ventana o FUERA del marco (sobre la pared)?"

Paso 2: Instrucciones seg√∫n respuesta
- Si es DENTRO del marco: "Mide el ANCHO exacto de extremo a extremo en la parte superior. Luego mide el ALTO. Restaremos 1cm al ancho para que encaje perfecto."
- Si es FUERA del marco: "Mide el ancho de la ventana y AGREGA 10cm a cada lado (20cm total) para cubrir bien. Al alto agr√©gale 15cm arriba y abajo."

Paso 3: Confirmaci√≥n
- "Por favor, ind√≠came las medidas finales en formato: ANCHO x ALTO (ejemplo: 1.50m ancho x 2.00m alto)."

REGLAS DE COMPORTAMIENTO:
- S√© amable, profesional y paciente.
- Usa emojis relacionados (üìè, ü™ü, ‚ú®, üè†).
- NO des precios finales exactos sin medidas, da "precios desde" o estimados.
- Si el usuario no sabe medir, ofr√©cele la gu√≠a paso a paso.
- Responde siempre en Espa√±ol.
"""


@app.route('/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'service': 'gemini_service',
        'model': GEMINI_MODEL,
        'api_key_configured': bool(GEMINI_API_KEY)
    }), 200


@app.route('/chat', methods=['POST'])
def chat():
    """
    Endpoint principal para conversaciones con Gemini
    
    Acepta:
    - JSON: {"message": "texto", "from_number": "identificador"}
    - Text/plain: mensaje directo (usa header X-WhatsApp-From para identificar usuario)
    
    Retorna:
    - JSON: {"response": "respuesta de Gemini"}
    """
    try:
        # Extraer mensaje y n√∫mero del usuario
        if request.is_json:
            data = request.get_json()
            message = data.get('message', '')
            from_number = data.get('from_number', 'unknown')
        else:
            message = request.get_data(as_text=True) or ''
            from_number = request.headers.get('X-WhatsApp-From', 'unknown')
        
        if not message:
            return jsonify({'error': 'No message provided'}), 400
        
        logger.info(f'üì® Mensaje de {from_number}: {message}')
        
        # Verificar API key
        if not GEMINI_API_KEY:
            logger.error('‚ùå GEMINI_API_KEY no configurada')
            return jsonify({
                'response': 'Lo siento, el servicio de IA no est√° configurado correctamente. Por favor contacta al administrador.'
            }), 500
        
        # Obtener o crear historial para este usuario
        if from_number not in conversation_history:
            conversation_history[from_number] = []
            logger.info(f'üÜï Nueva conversaci√≥n iniciada para {from_number}')
        
        # Agregar mensaje del usuario al historial
        conversation_history[from_number].append({
            'role': 'user',
            'parts': [message]
        })
        
        # Limitar tama√±o del historial
        if len(conversation_history[from_number]) > MAX_HISTORY_LENGTH * 2:
            # Mantener solo los √∫ltimos MAX_HISTORY_LENGTH intercambios (user + model)
            conversation_history[from_number] = conversation_history[from_number][-(MAX_HISTORY_LENGTH * 2):]
            logger.info(f'üóëÔ∏è  Historial recortado para {from_number}')
        
        # Crear modelo con configuraci√≥n
        model = genai.GenerativeModel(
            model_name=GEMINI_MODEL,
            system_instruction=SYSTEM_PROMPT
        )
        
        # Iniciar chat con historial
        chat = model.start_chat(history=conversation_history[from_number][:-1])
        
        # Enviar mensaje y obtener respuesta
        response = chat.send_message(message)
        response_text = response.text
        
        # Agregar respuesta al historial
        conversation_history[from_number].append({
            'role': 'model',
            'parts': [response_text]
        })
        
        logger.info(f'ü§ñ Respuesta para {from_number}: {response_text[:100]}...')
        
        return jsonify({
            'response': response_text,
            'from_number': from_number,
            'timestamp': datetime.utcnow().isoformat() + 'Z'
        }), 200
        
    except Exception as e:
        logger.exception(f'‚ùå Error procesando mensaje: {e}')
        return jsonify({
            'response': 'Lo siento, ocurri√≥ un error al procesar tu mensaje. Por favor intenta de nuevo.',
            'error': str(e)
        }), 500


@app.route('/clear_history', methods=['POST'])
def clear_history():
    """
    Limpia el historial conversacional de un usuario espec√≠fico o de todos
    
    Acepta:
    - JSON: {"from_number": "identificador"} - Limpia solo ese usuario
    - Sin body: Limpia todo el historial
    """
    try:
        if request.is_json:
            data = request.get_json()
            from_number = data.get('from_number')
            if from_number and from_number in conversation_history:
                del conversation_history[from_number]
                logger.info(f'üóëÔ∏è  Historial limpiado para {from_number}')
                return jsonify({'message': f'Historial limpiado para {from_number}'}), 200
            elif from_number:
                return jsonify({'message': f'No hay historial para {from_number}'}), 404
        
        # Limpiar todo el historial
        conversation_history.clear()
        logger.info('üóëÔ∏è  Todo el historial conversacional limpiado')
        return jsonify({'message': 'Todo el historial limpiado'}), 200
        
    except Exception as e:
        logger.exception(f'‚ùå Error limpiando historial: {e}')
        return jsonify({'error': str(e)}), 500


@app.route('/history', methods=['GET'])
def get_history():
    """
    Obtiene el historial conversacional (√∫til para debugging)
    
    Query params:
    - from_number: Obtener historial de un usuario espec√≠fico
    """
    try:
        from_number = request.args.get('from_number')
        
        if from_number:
            if from_number in conversation_history:
                return jsonify({
                    'from_number': from_number,
                    'history': conversation_history[from_number]
                }), 200
            else:
                return jsonify({
                    'from_number': from_number,
                    'history': []
                }), 200
        
        # Retornar estad√≠sticas generales
        return jsonify({
            'total_users': len(conversation_history),
            'users': list(conversation_history.keys())
        }), 200
        
    except Exception as e:
        logger.exception(f'‚ùå Error obteniendo historial: {e}')
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    logger.info('üöÄ Iniciando Gemini AI Service...')
    app.run(host='0.0.0.0', port=5003, debug=False)
